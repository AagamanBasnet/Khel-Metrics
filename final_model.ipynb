{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959644bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 → RMSE: 0.935, R²: 0.477, MatchAcc: 68.29%\n",
      "Fold 2 → RMSE: 0.893, R²: 0.525, MatchAcc: 62.93%\n",
      "Fold 3 → RMSE: 0.845, R²: 0.584, MatchAcc: 65.37%\n",
      "Fold 4 → RMSE: 0.824, R²: 0.605, MatchAcc: 65.85%\n",
      "Fold 5 → RMSE: 0.751, R²: 0.552, MatchAcc: 66.83%\n",
      "\n",
      "Average CV → RMSE: 0.850, R²: 0.549, Accuracy: 65.85%\n",
      " Calibrator trained.\n",
      " Final models saved.\n",
      "✅ Simulation saved.\n",
      " Running 10000 season simulations on cpu...\n",
      "  Monte Carlo Season Simulation Completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import poisson\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# CONFIG \n",
    "DATA_PATH = r\"data2_filled_safe.csv\"\n",
    "SPLIT_DATE = pd.to_datetime(\"2025-11-01\")\n",
    "INITIAL_ELO = 1500\n",
    "N_SIM = 5000\n",
    "MAX_GOALS = 10\n",
    "CV_FOLDS = 5\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#  LOAD DATA \n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['match_date'] = pd.to_datetime(df['match_date'], errors='coerce')\n",
    "df = df.sort_values('match_date').reset_index(drop=True)\n",
    "\n",
    "#  Keep original team names \n",
    "df['home_team_name_orig'] = df['home_team']\n",
    "df['away_team_name_orig'] = df['away_team']\n",
    "\n",
    "#  Encode categorical features for modeling \n",
    "for col in ['home_team', 'away_team']:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "#  Feature Engineering \n",
    "df['match_id'] = np.arange(len(df))\n",
    "if 'home_elo' not in df.columns or df['home_elo'].isnull().all():\n",
    "    df['home_elo'] = INITIAL_ELO\n",
    "    df['away_elo'] = INITIAL_ELO\n",
    "df['match_num_home'] = df.groupby('home_team').cumcount() + 1\n",
    "df['match_num_away'] = df.groupby('away_team').cumcount() + 1\n",
    "\n",
    "#  Features \n",
    "feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "feature_cols = [c for c in feature_cols if c not in ['home_goals','away_goals']]\n",
    "\n",
    "train_df = df[df['match_date'] < SPLIT_DATE].copy()\n",
    "test_df = df[df['match_date'] >= SPLIT_DATE].copy()\n",
    "y_train_home = train_df['home_goals']\n",
    "y_train_away = train_df['away_goals']\n",
    "\n",
    "#  Impute \n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_train = pd.DataFrame(imp.fit_transform(train_df[feature_cols]), columns=feature_cols)\n",
    "X_test = pd.DataFrame(imp.transform(test_df[feature_cols]), columns=feature_cols)\n",
    "\n",
    "#  XGBoost Poisson parameters \n",
    "xgb_params = {\n",
    "    \"objective\": \"count:poisson\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.85,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_lambda\": 1.2,\n",
    "    \"seed\": SEED,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"verbosity\": 0\n",
    "}\n",
    "\n",
    "#  CV with XGBoost \n",
    "tscv = TimeSeriesSplit(n_splits=CV_FOLDS)\n",
    "oof_preds = np.zeros((len(train_df), 2))\n",
    "oof_probs = np.zeros((len(train_df), 3))\n",
    "oof_true_outcome = np.full(len(train_df), -1, dtype=int)\n",
    "cv_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr_home, y_val_home = y_train_home.iloc[train_idx], y_train_home.iloc[val_idx]\n",
    "    y_tr_away, y_val_away = y_train_away.iloc[train_idx], y_train_away.iloc[val_idx]\n",
    "\n",
    "    dtrain_home = xgb.DMatrix(X_tr, label=y_tr_home)\n",
    "    dval_home = xgb.DMatrix(X_val, label=y_val_home)\n",
    "    dtrain_away = xgb.DMatrix(X_tr, label=y_tr_away)\n",
    "    dval_away = xgb.DMatrix(X_val, label=y_val_away)\n",
    "\n",
    "    evals_home = [(dtrain_home, 'train'), (dval_home, 'eval')]\n",
    "    evals_away = [(dtrain_away, 'train'), (dval_away, 'eval')]\n",
    "\n",
    "    home_model = xgb.train(xgb_params, dtrain_home, num_boost_round=2000, evals=evals_home,\n",
    "                           early_stopping_rounds=50, verbose_eval=False)\n",
    "    away_model = xgb.train(xgb_params, dtrain_away, num_boost_round=2000, evals=evals_away,\n",
    "                           early_stopping_rounds=50, verbose_eval=False)\n",
    "\n",
    "    pred_val_home = home_model.predict(dval_home).clip(0.05, 10)\n",
    "    pred_val_away = away_model.predict(dval_away).clip(0.05, 10)\n",
    "    oof_preds[val_idx, 0] = pred_val_home\n",
    "    oof_preds[val_idx, 1] = pred_val_away\n",
    "\n",
    "    for i, idx in enumerate(val_idx):\n",
    "        ph = poisson.pmf(np.arange(MAX_GOALS+1), pred_val_home[i])\n",
    "        pa = poisson.pmf(np.arange(MAX_GOALS+1), pred_val_away[i])\n",
    "        joint = np.outer(ph, pa)\n",
    "        oof_probs[idx] = [np.tril(joint, -1).sum(), np.trace(joint), np.triu(joint, 1).sum()]\n",
    "\n",
    "    h_goals = y_val_home.values\n",
    "    a_goals = y_val_away.values\n",
    "    oof_true_outcome[val_idx] = np.where(h_goals>a_goals,0,np.where(h_goals==a_goals,1,2))\n",
    "\n",
    "    rmse_home = np.sqrt(np.mean((h_goals - pred_val_home)**2))\n",
    "    rmse_away = np.sqrt(np.mean((a_goals - pred_val_away)**2))\n",
    "    r2_home = r2_score(h_goals, pred_val_home)\n",
    "    r2_away = r2_score(a_goals, pred_val_away)\n",
    "    match_acc = np.mean(np.sign(h_goals - a_goals) == np.sign(pred_val_home - pred_val_away))\n",
    "    cv_metrics.append(((rmse_home+rmse_away)/2,(r2_home+r2_away)/2,match_acc))\n",
    "    print(f\"Fold {fold} → RMSE: {(rmse_home+rmse_away)/2:.3f}, R²: {(r2_home+r2_away)/2:.3f}, MatchAcc: {match_acc*100:.2f}%\")\n",
    "\n",
    "cv_rmse = np.mean([m[0] for m in cv_metrics])\n",
    "cv_r2 = np.mean([m[1] for m in cv_metrics])\n",
    "cv_acc = np.mean([m[2] for m in cv_metrics])\n",
    "print(f\"\\nAverage CV → RMSE: {cv_rmse:.3f}, R²: {cv_r2:.3f}, Accuracy: {cv_acc*100:.2f}%\")\n",
    "\n",
    "#  Calibration \n",
    "has_true = oof_true_outcome >= 0\n",
    "if has_true.sum() >= 50:\n",
    "    calibrator = LogisticRegression(max_iter=2000, solver='lbfgs', random_state=SEED)\n",
    "    calibrator.fit(oof_probs[has_true], oof_true_outcome[has_true])\n",
    "    print(\" Calibrator trained.\")\n",
    "else:\n",
    "    calibrator = None\n",
    "    print(\" Not enough OOF data for calibration.\")\n",
    "\n",
    "#  Final XGBoost models \n",
    "dtrain_home_full = xgb.DMatrix(X_train, label=y_train_home)\n",
    "dtrain_away_full = xgb.DMatrix(X_train, label=y_train_away)\n",
    "home_final = xgb.train(xgb_params, dtrain_home_full, num_boost_round=2000,\n",
    "                       evals=[(dtrain_home_full,'train')], early_stopping_rounds=50, verbose_eval=False)\n",
    "away_final = xgb.train(xgb_params, dtrain_away_full, num_boost_round=2000,\n",
    "                       evals=[(dtrain_away_full,'train')], early_stopping_rounds=50, verbose_eval=False)\n",
    "feature_cols = X_train.columns.tolist()\n",
    "joblib.dump(feature_cols, \"feature_cols.pkl\")\n",
    "\n",
    "joblib.dump(home_final, \"home_xgb_poisson.pkl\")\n",
    "joblib.dump(away_final, \"away_xgb_poisson.pkl\")\n",
    "print(\" Final models saved.\")\n",
    "\n",
    "#  Predict test set \n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_test_home = home_final.predict(dtest).clip(0.05,10)\n",
    "y_pred_test_away = away_final.predict(dtest).clip(0.05,10)\n",
    "\n",
    "\n",
    "\n",
    "#  Monte Carlo simulation \n",
    "homes = np.random.poisson(y_pred_test_home[:,None], (len(y_pred_test_home), N_SIM))\n",
    "aways = np.random.poisson(y_pred_test_away[:,None], (len(y_pred_test_away), N_SIM))\n",
    "sim_results = test_df[['match_date','home_team_name_orig','away_team_name_orig']].copy()\n",
    "sim_results['exp_home_goals'] = homes.mean(axis=1)\n",
    "sim_results['exp_away_goals'] = aways.mean(axis=1)\n",
    "sim_results['prob_home_win'] = (homes>aways).mean(axis=1)\n",
    "sim_results['prob_draw'] = (homes==aways).mean(axis=1)\n",
    "sim_results['prob_away_win'] = (homes<aways).mean(axis=1)\n",
    "sim_results = sim_results.rename(columns={'home_team_name_orig':'home_team_name','away_team_name_orig':'away_team_name'})\n",
    "sim_results.to_csv(\"simulated_matches_with_probs.csv\", index=False)\n",
    "print(\"✅ Simulation saved.\")\n",
    "\n",
    "#  Season simulation \n",
    "N_SEASON_SIM = 10000 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "\n",
    "matches = sim_results.copy()\n",
    "teams = pd.unique(pd.concat([matches['home_team_name'], matches['away_team_name']]))\n",
    "\n",
    "team_to_idx = {t: i for i, t in enumerate(teams)}\n",
    "n_teams = len(teams)\n",
    "n_matches = len(matches)\n",
    "\n",
    "print(f\" Running {N_SEASON_SIM} season simulations on {DEVICE}...\")\n",
    "\n",
    "# Convert match data into GPU tensors\n",
    "home_idx = torch.tensor(matches['home_team_name'].map(team_to_idx).values, device=DEVICE)\n",
    "away_idx = torch.tensor(matches['away_team_name'].map(team_to_idx).values, device=DEVICE)\n",
    "\n",
    "prob_home = torch.tensor(matches['prob_home_win'].values, device=DEVICE)\n",
    "prob_draw = torch.tensor(matches['prob_draw'].values, device=DEVICE)\n",
    "prob_away = torch.tensor(matches['prob_away_win'].values, device=DEVICE)\n",
    "\n",
    "exp_home_goals = torch.tensor(matches['exp_home_goals'].values, device=DEVICE)\n",
    "exp_away_goals = torch.tensor(matches['exp_away_goals'].values, device=DEVICE)\n",
    "\n",
    "# Srorage\n",
    "season_points_all = {t: [] for t in teams}\n",
    "season_positions_all = {t: [] for t in teams}\n",
    "\n",
    "# Precompute categorical distributions for match outcomes\n",
    "probs = torch.stack([prob_home, prob_draw, prob_away], dim=1)\n",
    "\n",
    "for sim in range(N_SEASON_SIM):\n",
    "\n",
    "    # Empty table per simulation (GPU tensor)\n",
    "    points = torch.zeros(n_teams, device=DEVICE)\n",
    "    gf = torch.zeros(n_teams, device=DEVICE)\n",
    "    ga = torch.zeros(n_teams, device=DEVICE)\n",
    "\n",
    "    # Draw match outcomes\n",
    "    outcomes = torch.multinomial(probs, 1).squeeze(1)  \n",
    "    # 0 = Home Win, 1 = Draw, 2 = Away Win\n",
    "\n",
    "    # Draw Poisson goals \n",
    "    gh = torch.poisson(exp_home_goals).float()\n",
    "    ga_ = torch.poisson(exp_away_goals).float()\n",
    "\n",
    "\n",
    "    # Update goals\n",
    "    gf.index_add_(0, home_idx, gh)\n",
    "    ga.index_add_(0, home_idx, ga_)\n",
    "    gf.index_add_(0, away_idx, ga_)\n",
    "    ga.index_add_(0, away_idx, gh)\n",
    "\n",
    "    # Update points\n",
    "    # Home win\n",
    "    mask = (outcomes == 0)\n",
    "    points.index_add_(0, home_idx[mask], torch.ones(mask.sum(), device=DEVICE) * 3)\n",
    "\n",
    "    # Away win\n",
    "    mask = (outcomes == 2)\n",
    "    points.index_add_(0, away_idx[mask], torch.ones(mask.sum(), device=DEVICE) * 3)\n",
    "\n",
    "    # Draw\n",
    "    mask = (outcomes == 1)\n",
    "    points.index_add_(0, home_idx[mask], torch.ones(mask.sum(), device=DEVICE))\n",
    "    points.index_add_(0, away_idx[mask], torch.ones(mask.sum(), device=DEVICE))\n",
    "\n",
    "    # Ranking \n",
    "    goal_diff = gf - ga\n",
    "    table = torch.stack([points, goal_diff, gf], dim=1)\n",
    "\n",
    "    # Sort by (points desc, goal_diff desc, goals_for desc)\n",
    "    _, order = torch.sort(table, dim=0, descending=True)\n",
    "    order = order[:, 0]  # only sort by first key (points), PyTorch keeps tie order stable\n",
    "\n",
    "    # Record positions and points\n",
    "    for pos, team_idx in enumerate(order.tolist()):\n",
    "        team = teams[team_idx]\n",
    "        season_positions_all[team].append(pos + 1)\n",
    "        season_points_all[team].append(points[team_idx].item())\n",
    "\n",
    "print(\"  Monte Carlo Season Simulation Completed!\")\n",
    "summary = pd.DataFrame({'team': teams})\n",
    "\n",
    "summary['avg_points'] = summary['team'].apply(lambda t: np.mean(season_points_all[t]))\n",
    "summary['std_points'] = summary['team'].apply(lambda t: np.std(season_points_all[t]))\n",
    "\n",
    "summary['prob_win_league'] = summary['team'].apply(lambda t: \n",
    "    np.mean(np.array(season_positions_all[t]) == 1)\n",
    ")\n",
    "\"\"\"  \"\"\"\n",
    "summary['prob_top4'] = summary['team'].apply(lambda t: \n",
    "    np.mean(np.array(season_positions_all[t]) <= 4)\n",
    ")\n",
    "\n",
    "summary['prob_relegation'] = summary['team'].apply(lambda t: \n",
    "    np.mean(np.array(season_positions_all[t]) >= len(teams)-2)\n",
    ")\n",
    "\n",
    "summary['avg_position'] = summary['team'].apply(lambda t: \n",
    "    np.mean(season_positions_all[t])\n",
    ")\n",
    "\n",
    "summary = summary.sort_values('avg_position')\n",
    "\n",
    "summary.to_csv(\"season_simulation_distributions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8fed904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Set Evaluation:\n",
      "Home RMSE: 0.673, Away RMSE: 0.671\n",
      "Home R²: 0.649, Away R²: 0.196\n",
      "Match Outcome Accuracy: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predictions\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_home = home_final.predict(dtest).clip(0.05, 10)\n",
    "y_pred_away = away_final.predict(dtest).clip(0.05, 10)\n",
    "\n",
    "# True values\n",
    "y_true_home = test_df['home_goals'].values\n",
    "y_true_away = test_df['away_goals'].values\n",
    "\n",
    "# Mask rows without NaNs\n",
    "mask = (~np.isnan(y_true_home)) & (~np.isnan(y_true_away)) & (~np.isnan(y_pred_home)) & (~np.isnan(y_pred_away))\n",
    "\n",
    "y_true_home = y_true_home[mask]\n",
    "y_true_away = y_true_away[mask]\n",
    "y_pred_home = y_pred_home[mask]\n",
    "y_pred_away = y_pred_away[mask]\n",
    "\n",
    "# RMSE using np.sqrt\n",
    "rmse_home = np.sqrt(np.mean((y_true_home - y_pred_home)**2))\n",
    "rmse_away = np.sqrt(np.mean((y_true_away - y_pred_away)**2))\n",
    "\n",
    "# R²\n",
    "r2_home = r2_score(y_true_home, y_pred_home)\n",
    "r2_away = r2_score(y_true_away, y_pred_away)\n",
    "\n",
    "# Match outcome accuracy\n",
    "pred_outcome = np.sign(y_pred_home - y_pred_away)\n",
    "true_outcome = np.sign(y_true_home - y_true_away)\n",
    "match_acc = np.mean(pred_outcome == true_outcome)\n",
    "\n",
    "print(f\" Test Set Evaluation:\")\n",
    "print(f\"Home RMSE: {rmse_home:.3f}, Away RMSE: {rmse_away:.3f}\")\n",
    "print(f\"Home R²: {r2_home:.3f}, Away R²: {r2_away:.3f}\")\n",
    "print(f\"Match Outcome Accuracy: {match_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c7e91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
