{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "959644bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 → RMSE: 0.948, R²: 0.476, MatchAcc: 68.93%\n",
      "Fold 2 → RMSE: 0.899, R²: 0.533, MatchAcc: 65.53%\n",
      "Fold 3 → RMSE: 0.819, R²: 0.597, MatchAcc: 65.05%\n",
      "Fold 4 → RMSE: 0.814, R²: 0.601, MatchAcc: 66.99%\n",
      "Fold 5 → RMSE: 0.755, R²: 0.551, MatchAcc: 67.48%\n",
      "\n",
      "Average CV → RMSE: 0.847, R²: 0.552, Accuracy: 66.80%\n",
      " Calibrator trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Predictor\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final models saved.\n",
      "✅ Simulation saved.\n",
      " Running 10000 season simulations on cpu...\n",
      "  Monte Carlo Season Simulation Completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import poisson\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "# CONFIG \n",
    "DATA_PATH = r\"D:\\Predictor\\khel_metrics\\science_exhibition\\data2_filled_safe.csv\"\n",
    "SPLIT_DATE = pd.to_datetime(\"2025-11-07\")\n",
    "INITIAL_ELO = 1500\n",
    "N_SIM = 5000\n",
    "MAX_GOALS = 10\n",
    "CV_FOLDS = 5\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#  LOAD DATA \n",
    "df = pd.read_csv(DATA_PATH)\n",
    "df['match_date'] = pd.to_datetime(df['match_date'], errors='coerce')\n",
    "df = df.sort_values('match_date').reset_index(drop=True)\n",
    "\n",
    "#  Keep original team names \n",
    "df['home_team_name_orig'] = df['home_team']\n",
    "df['away_team_name_orig'] = df['away_team']\n",
    "\n",
    "#  Encode categorical features for modeling \n",
    "for col in ['home_team', 'away_team']:\n",
    "    df[col] = df[col].astype('category').cat.codes\n",
    "\n",
    "#  Feature Engineering \n",
    "df['match_id'] = np.arange(len(df))\n",
    "if 'home_elo' not in df.columns or df['home_elo'].isnull().all():\n",
    "    df['home_elo'] = INITIAL_ELO\n",
    "    df['away_elo'] = INITIAL_ELO\n",
    "df['match_num_home'] = df.groupby('home_team').cumcount() + 1\n",
    "df['match_num_away'] = df.groupby('away_team').cumcount() + 1\n",
    "\n",
    "#  Features \n",
    "feature_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "feature_cols = [c for c in feature_cols if c not in ['home_goals','away_goals']]\n",
    "\n",
    "train_df = df[df['match_date'] < SPLIT_DATE].copy()\n",
    "test_df = df[df['match_date'] >= SPLIT_DATE].copy()\n",
    "y_train_home = train_df['home_goals']\n",
    "y_train_away = train_df['away_goals']\n",
    "\n",
    "#  Impute \n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_train = pd.DataFrame(imp.fit_transform(train_df[feature_cols]), columns=feature_cols)\n",
    "X_test = pd.DataFrame(imp.transform(test_df[feature_cols]), columns=feature_cols)\n",
    "\n",
    "#  XGBoost Poisson parameters \n",
    "xgb_params = {\n",
    "    \"objective\": \"count:poisson\",\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.85,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"reg_lambda\": 1.2,\n",
    "    \"seed\": SEED,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"verbosity\": 0\n",
    "}\n",
    "\n",
    "#  CV with XGBoost \n",
    "tscv = TimeSeriesSplit(n_splits=CV_FOLDS)\n",
    "oof_preds = np.zeros((len(train_df), 2))\n",
    "oof_probs = np.zeros((len(train_df), 3))\n",
    "oof_true_outcome = np.full(len(train_df), -1, dtype=int)\n",
    "cv_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n",
    "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_tr_home, y_val_home = y_train_home.iloc[train_idx], y_train_home.iloc[val_idx]\n",
    "    y_tr_away, y_val_away = y_train_away.iloc[train_idx], y_train_away.iloc[val_idx]\n",
    "\n",
    "    dtrain_home = xgb.DMatrix(X_tr, label=y_tr_home)\n",
    "    dval_home = xgb.DMatrix(X_val, label=y_val_home)\n",
    "    dtrain_away = xgb.DMatrix(X_tr, label=y_tr_away)\n",
    "    dval_away = xgb.DMatrix(X_val, label=y_val_away)\n",
    "\n",
    "    evals_home = [(dtrain_home, 'train'), (dval_home, 'eval')]\n",
    "    evals_away = [(dtrain_away, 'train'), (dval_away, 'eval')]\n",
    "\n",
    "    home_model = xgb.train(xgb_params, dtrain_home, num_boost_round=2000, evals=evals_home,\n",
    "                           early_stopping_rounds=50, verbose_eval=False)\n",
    "    away_model = xgb.train(xgb_params, dtrain_away, num_boost_round=2000, evals=evals_away,\n",
    "                           early_stopping_rounds=50, verbose_eval=False)\n",
    "\n",
    "    pred_val_home = home_model.predict(dval_home).clip(0.05, 10)\n",
    "    pred_val_away = away_model.predict(dval_away).clip(0.05, 10)\n",
    "    oof_preds[val_idx, 0] = pred_val_home\n",
    "    oof_preds[val_idx, 1] = pred_val_away\n",
    "\n",
    "    for i, idx in enumerate(val_idx):\n",
    "        ph = poisson.pmf(np.arange(MAX_GOALS+1), pred_val_home[i])\n",
    "        pa = poisson.pmf(np.arange(MAX_GOALS+1), pred_val_away[i])\n",
    "        joint = np.outer(ph, pa)\n",
    "        oof_probs[idx] = [np.tril(joint, -1).sum(), np.trace(joint), np.triu(joint, 1).sum()]\n",
    "\n",
    "    h_goals = y_val_home.values\n",
    "    a_goals = y_val_away.values\n",
    "    oof_true_outcome[val_idx] = np.where(h_goals>a_goals,0,np.where(h_goals==a_goals,1,2))\n",
    "\n",
    "    rmse_home = np.sqrt(np.mean((h_goals - pred_val_home)**2))\n",
    "    rmse_away = np.sqrt(np.mean((a_goals - pred_val_away)**2))\n",
    "    r2_home = r2_score(h_goals, pred_val_home)\n",
    "    r2_away = r2_score(a_goals, pred_val_away)\n",
    "    match_acc = np.mean(np.sign(h_goals - a_goals) == np.sign(pred_val_home - pred_val_away))\n",
    "    cv_metrics.append(((rmse_home+rmse_away)/2,(r2_home+r2_away)/2,match_acc))\n",
    "    print(f\"Fold {fold} → RMSE: {(rmse_home+rmse_away)/2:.3f}, R²: {(r2_home+r2_away)/2:.3f}, MatchAcc: {match_acc*100:.2f}%\")\n",
    "\n",
    "cv_rmse = np.mean([m[0] for m in cv_metrics])\n",
    "cv_r2 = np.mean([m[1] for m in cv_metrics])\n",
    "cv_acc = np.mean([m[2] for m in cv_metrics])\n",
    "print(f\"\\nAverage CV → RMSE: {cv_rmse:.3f}, R²: {cv_r2:.3f}, Accuracy: {cv_acc*100:.2f}%\")\n",
    "\n",
    "#  Calibration \n",
    "has_true = oof_true_outcome >= 0\n",
    "if has_true.sum() >= 50:\n",
    "    calibrator = LogisticRegression(multi_class='multinomial', max_iter=2000, solver='lbfgs', random_state=SEED)\n",
    "    calibrator.fit(oof_probs[has_true], oof_true_outcome[has_true])\n",
    "    print(\" Calibrator trained.\")\n",
    "else:\n",
    "    calibrator = None\n",
    "    print(\" Not enough OOF data for calibration.\")\n",
    "\n",
    "#  Final XGBoost models \n",
    "dtrain_home_full = xgb.DMatrix(X_train, label=y_train_home)\n",
    "dtrain_away_full = xgb.DMatrix(X_train, label=y_train_away)\n",
    "home_final = xgb.train(xgb_params, dtrain_home_full, num_boost_round=2000,\n",
    "                       evals=[(dtrain_home_full,'train')], early_stopping_rounds=50, verbose_eval=False)\n",
    "away_final = xgb.train(xgb_params, dtrain_away_full, num_boost_round=2000,\n",
    "                       evals=[(dtrain_away_full,'train')], early_stopping_rounds=50, verbose_eval=False)\n",
    "feature_cols = X_train.columns.tolist()\n",
    "joblib.dump(feature_cols, \"feature_cols.pkl\")\n",
    "\n",
    "joblib.dump(home_final, \"home_xgb_poisson.pkl\")\n",
    "joblib.dump(away_final, \"away_xgb_poisson.pkl\")\n",
    "print(\" Final models saved.\")\n",
    "\n",
    "#  Predict test set \n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_test_home = home_final.predict(dtest).clip(0.05,10)\n",
    "y_pred_test_away = away_final.predict(dtest).clip(0.05,10)\n",
    "\n",
    "\n",
    "\n",
    "#  Monte Carlo simulation \n",
    "homes = np.random.poisson(y_pred_test_home[:,None], (len(y_pred_test_home), N_SIM))\n",
    "aways = np.random.poisson(y_pred_test_away[:,None], (len(y_pred_test_away), N_SIM))\n",
    "sim_results = test_df[['match_date','home_team_name_orig','away_team_name_orig']].copy()\n",
    "sim_results['exp_home_goals'] = homes.mean(axis=1)\n",
    "sim_results['exp_away_goals'] = aways.mean(axis=1)\n",
    "sim_results['prob_home_win'] = (homes>aways).mean(axis=1)\n",
    "sim_results['prob_draw'] = (homes==aways).mean(axis=1)\n",
    "sim_results['prob_away_win'] = (homes<aways).mean(axis=1)\n",
    "sim_results = sim_results.rename(columns={'home_team_name_orig':'home_team_name','away_team_name_orig':'away_team_name'})\n",
    "sim_results.to_csv(\"simulated_matches_with_probs.csv\", index=False)\n",
    "print(\"✅ Simulation saved.\")\n",
    "\n",
    "#  Season simulation \n",
    "N_SEASON_SIM = 10000 \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(42)\n",
    "\n",
    "matches = sim_results.copy()\n",
    "teams = pd.unique(pd.concat([matches['home_team_name'], matches['away_team_name']]))\n",
    "\n",
    "team_to_idx = {t: i for i, t in enumerate(teams)}\n",
    "n_teams = len(teams)\n",
    "n_matches = len(matches)\n",
    "\n",
    "print(f\" Running {N_SEASON_SIM} season simulations on {DEVICE}...\")\n",
    "\n",
    "# Convert match data into GPU tensors\n",
    "home_idx = torch.tensor(matches['home_team_name'].map(team_to_idx).values, device=DEVICE)\n",
    "away_idx = torch.tensor(matches['away_team_name'].map(team_to_idx).values, device=DEVICE)\n",
    "\n",
    "prob_home = torch.tensor(matches['prob_home_win'].values, device=DEVICE)\n",
    "prob_draw = torch.tensor(matches['prob_draw'].values, device=DEVICE)\n",
    "prob_away = torch.tensor(matches['prob_away_win'].values, device=DEVICE)\n",
    "\n",
    "exp_home_goals = torch.tensor(matches['exp_home_goals'].values, device=DEVICE)\n",
    "exp_away_goals = torch.tensor(matches['exp_away_goals'].values, device=DEVICE)\n",
    "\n",
    "# Srorage\n",
    "season_points_all = {t: [] for t in teams}\n",
    "season_positions_all = {t: [] for t in teams}\n",
    "\n",
    "# Precompute categorical distributions for match outcomes\n",
    "probs = torch.stack([prob_home, prob_draw, prob_away], dim=1)\n",
    "\n",
    "for sim in range(N_SEASON_SIM):\n",
    "\n",
    "    # Empty table per simulation (GPU tensor)\n",
    "    points = torch.zeros(n_teams, device=DEVICE)\n",
    "    gf = torch.zeros(n_teams, device=DEVICE)\n",
    "    ga = torch.zeros(n_teams, device=DEVICE)\n",
    "\n",
    "    # Draw match outcomes\n",
    "    outcomes = torch.multinomial(probs, 1).squeeze(1)  \n",
    "    # 0 = Home Win, 1 = Draw, 2 = Away Win\n",
    "\n",
    "    # Draw Poisson goals \n",
    "    gh = torch.poisson(exp_home_goals).float()\n",
    "    ga_ = torch.poisson(exp_away_goals).float()\n",
    "\n",
    "\n",
    "    # Update goals\n",
    "    gf.index_add_(0, home_idx, gh)\n",
    "    ga.index_add_(0, home_idx, ga_)\n",
    "    gf.index_add_(0, away_idx, ga_)\n",
    "    ga.index_add_(0, away_idx, gh)\n",
    "\n",
    "    # Update points\n",
    "    # Home win\n",
    "    mask = (outcomes == 0)\n",
    "    points.index_add_(0, home_idx[mask], torch.ones(mask.sum(), device=DEVICE) * 3)\n",
    "\n",
    "    # Away win\n",
    "    mask = (outcomes == 2)\n",
    "    points.index_add_(0, away_idx[mask], torch.ones(mask.sum(), device=DEVICE) * 3)\n",
    "\n",
    "    # Draw\n",
    "    mask = (outcomes == 1)\n",
    "    points.index_add_(0, home_idx[mask], torch.ones(mask.sum(), device=DEVICE))\n",
    "    points.index_add_(0, away_idx[mask], torch.ones(mask.sum(), device=DEVICE))\n",
    "\n",
    "    # Ranking \n",
    "    goal_diff = gf - ga\n",
    "    table = torch.stack([points, goal_diff, gf], dim=1)\n",
    "\n",
    "    # Sort by (points desc, goal_diff desc, goals_for desc)\n",
    "    _, order = torch.sort(table, dim=0, descending=True)\n",
    "    order = order[:, 0]  # only sort by first key (points), PyTorch keeps tie order stable\n",
    "\n",
    "    # Record positions and points\n",
    "    for pos, team_idx in enumerate(order.tolist()):\n",
    "        team = teams[team_idx]\n",
    "        season_positions_all[team].append(pos + 1)\n",
    "        season_points_all[team].append(points[team_idx].item())\n",
    "\n",
    "print(\"  Monte Carlo Season Simulation Completed!\")\n",
    "summary = pd.DataFrame({'team': teams})\n",
    "\n",
    "summary['avg_points'] = summary['team'].apply(lambda t: np.mean(season_points_all[t]))\n",
    "summary['std_points'] = summary['team'].apply(lambda t: np.std(season_points_all[t]))\n",
    "\n",
    "summary['prob_win_league'] = summary['team'].apply(lambda t: \n",
    "    np.mean(np.array(season_positions_all[t]) == 1)\n",
    ")\n",
    "\"\"\"  \"\"\"\n",
    "summary['prob_top4'] = summary['team'].apply(lambda t: \n",
    "    np.mean(np.array(season_positions_all[t]) <= 4)\n",
    ")\n",
    "\n",
    "summary['prob_relegation'] = summary['team'].apply(lambda t: \n",
    "    np.mean(np.array(season_positions_all[t]) >= len(teams)-2)\n",
    ")\n",
    "\n",
    "summary['avg_position'] = summary['team'].apply(lambda t: \n",
    "    np.mean(season_positions_all[t])\n",
    ")\n",
    "\n",
    "summary = summary.sort_values('avg_position')\n",
    "\n",
    "summary.to_csv(\"season_simulation_distributions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fed904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Predictor\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice.\n",
      "\n",
      "d:\\Predictor\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in scalar divide\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m rmse_away = np.sqrt(np.mean((y_true_away - y_pred_away)**\u001b[32m2\u001b[39m))\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# R²\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m r2_home = \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_home\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_home\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m r2_away = r2_score(y_true_away, y_pred_away)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Match outcome accuracy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Predictor\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:1276\u001b[39m, in \u001b[36mr2_score\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[39m\n\u001b[32m   1152\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[32m   1153\u001b[39m \n\u001b[32m   1154\u001b[39m \u001b[33;03mBest possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1269\u001b[39m \u001b[33;03m-inf\u001b[39;00m\n\u001b[32m   1270\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1271\u001b[39m xp, _, device_ = get_namespace_and_device(\n\u001b[32m   1272\u001b[39m     y_true, y_pred, sample_weight, multioutput\n\u001b[32m   1273\u001b[39m )\n\u001b[32m   1275\u001b[39m _, y_true, y_pred, sample_weight, multioutput = (\n\u001b[32m-> \u001b[39m\u001b[32m1276\u001b[39m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1279\u001b[39m )\n\u001b[32m   1281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) < \u001b[32m2\u001b[39m:\n\u001b[32m   1282\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mR^2 score is not well-defined with less than two samples.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Predictor\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:209\u001b[39m, in \u001b[36m_check_reg_targets_with_floating_dtype\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Ensures y_true, y_pred, and sample_weight correspond to same regression task.\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[33;03mExtends `_check_reg_targets` by automatically selecting a suitable floating-point\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m \u001b[33;03m    correct keyword.\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    207\u001b[39m dtype_name = _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp=xp)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m y_type, y_true, y_pred, sample_weight, multioutput = \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y_type, y_true, y_pred, sample_weight, multioutput\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Predictor\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:115\u001b[39m, in \u001b[36m_check_reg_targets\u001b[39m\u001b[34m(y_true, y_pred, sample_weight, multioutput, dtype, xp)\u001b[39m\n\u001b[32m    112\u001b[39m xp, _ = get_namespace(y_true, y_pred, multioutput, xp=xp)\n\u001b[32m    114\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m y_true = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m y_pred = check_array(y_pred, ensure_2d=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=dtype)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Predictor\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1128\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1126\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1127\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1128\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1129\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1131\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1132\u001b[39m         )\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1135\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predictions\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "y_pred_home = home_final.predict(dtest).clip(0.05, 10)\n",
    "y_pred_away = away_final.predict(dtest).clip(0.05, 10)\n",
    "\n",
    "# True values\n",
    "y_true_home = test_df['home_goals'].values\n",
    "y_true_away = test_df['away_goals'].values\n",
    "\n",
    "# Mask rows without NaNs\n",
    "mask = (~np.isnan(y_true_home)) & (~np.isnan(y_true_away)) & (~np.isnan(y_pred_home)) & (~np.isnan(y_pred_away))\n",
    "\n",
    "y_true_home = y_true_home[mask]\n",
    "y_true_away = y_true_away[mask]\n",
    "y_pred_home = y_pred_home[mask]\n",
    "y_pred_away = y_pred_away[mask]\n",
    "\n",
    "# RMSE using np.sqrt\n",
    "rmse_home = np.sqrt(np.mean((y_true_home - y_pred_home)**2))\n",
    "rmse_away = np.sqrt(np.mean((y_true_away - y_pred_away)**2))\n",
    "\n",
    "# R²\n",
    "r2_home = r2_score(y_true_home, y_pred_home)\n",
    "r2_away = r2_score(y_true_away, y_pred_away)\n",
    "\n",
    "# Match outcome accuracy\n",
    "pred_outcome = np.sign(y_pred_home - y_pred_away)\n",
    "true_outcome = np.sign(y_true_home - y_true_away)\n",
    "match_acc = np.mean(pred_outcome == true_outcome)\n",
    "\n",
    "print(f\" Test Set Evaluation:\")\n",
    "print(f\"Home RMSE: {rmse_home:.3f}, Away RMSE: {rmse_away:.3f}\")\n",
    "print(f\"Home R²: {r2_home:.3f}, Away R²: {r2_away:.3f}\")\n",
    "print(f\"Match Outcome Accuracy: {match_acc*100:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
